{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Build and Evaluate LLM Applications using advanced RAG( using Llama Index and Trulens Frameworks)**"
      ],
      "metadata": {
        "id": "YRdFDKwQpxbf"
      },
      "id": "YRdFDKwQpxbf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we show how to use the Gemini text models from Google in LlamaIndex. Check out the Gemini site or the announcement.\n",
        "\n",
        "If you're opening this Notebook on colab, you will need to install LlamaIndex ðŸ¦™ and the Gemini Python SDK."
      ],
      "metadata": {
        "id": "XFpKIx1Qprw5"
      },
      "id": "XFpKIx1Qprw5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Optional] step to help restart the Colab Enterprise Notebook Google Cloud"
      ],
      "metadata": {
        "id": "l-TkZxlLmi9r"
      },
      "id": "l-TkZxlLmi9r"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "cAH9LFPvJXWb"
      },
      "id": "cAH9LFPvJXWb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the required pip packages for this Notebook"
      ],
      "metadata": {
        "id": "dxd7ZVsenWgi"
      },
      "id": "dxd7ZVsenWgi"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf cohere llama-index==0.9.48 google-generativeai trulens_eval==0.22.1 litellm==1.23.10 torch sentence-transformers"
      ],
      "metadata": {
        "id": "Nkh25545RW0L"
      },
      "id": "Nkh25545RW0L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the Environment variables for API Keys\n",
        "\n",
        "You will need to get an API key from [Google AI Studio](https:///makersuite.google.com/app/apikey). Once you have one, you can either pass it explicity to the model, or use the GOOGLE_API_KEY environment variable.\n"
      ],
      "metadata": {
        "id": "h6bW0uQVoCEu"
      },
      "id": "h6bW0uQVoCEu"
    },
    {
      "cell_type": "code",
      "source": [
        "%env GOOGLE_API_KEY=...\n",
        "%env GEMINI_API_KEY=..."
      ],
      "metadata": {
        "id": "KeA6GxV7cR7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952545847,
          "user_tz": 0,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9d030b1f-3cd7-4935-9a66-c70686585028"
      },
      "id": "KeA6GxV7cR7Q",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY=...\n",
            "env: GEMINI_API_KEY=...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = \"\"  # add your GOOGLE API key here\n",
        "GEMINI_API_KEY = \"\"  # add your GEMINI API key here\n",
        "OPEN_API_KEY = \"\" # add your OPEN API key here\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "os.environ[\"OPEN_API_KEY\"] = OPEN_API_KEY"
      ],
      "metadata": {
        "id": "-qKass9-cUDQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952546786,
          "user_tz": 0,
          "elapsed": 72,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "-qKass9-cUDQ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is solve the bug related to the typing_extensions incompatibility with the versions of the library we are using"
      ],
      "metadata": {
        "id": "DrH2fqI1pH8a"
      },
      "id": "DrH2fqI1pH8a"
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /usr/local/lib/python3.10/dist-packages/openai/_utils/_streams.py\n",
        "from typing import Any\n",
        "from typing_extensions import AsyncIterator\n",
        "from typing import Iterator # import Iterator from the correct library\n",
        "\n",
        "def consume_sync_iterator(iterator: Iterator[Any]) -> None:\n",
        "    for _ in iterator:\n",
        "        ...\n",
        "\n",
        "async def consume_async_iterator(iterator: AsyncIterator[Any]) -> None:\n",
        "    async for _ in iterator:\n",
        "        ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkDrx6U5YDjw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952548489,
          "user_tz": 0,
          "elapsed": 130,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ba11bb4c-4f07-4a85-856b-ab4784162a10"
      },
      "id": "HkDrx6U5YDjw",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /usr/local/lib/python3.10/dist-packages/openai/_utils/_streams.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An example to use the Gemini text models from Google in LlamaIndex"
      ],
      "metadata": {
        "id": "uSndH5JJqSRA"
      },
      "id": "uSndH5JJqSRA"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import Gemini\n",
        "\n",
        "\n",
        "resp = Gemini().complete(\"Write a poem about a magic backpack\")\n",
        "print(resp)"
      ],
      "metadata": {
        "id": "f5K6486oW6Gi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952194865,
          "user_tz": 0,
          "elapsed": 10987,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "50ad2b95-6958-4578-86c6-1470c3330437"
      },
      "id": "f5K6486oW6Gi",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**The Magic Backpack**\n",
            "\n",
            "In a realm where wonders reside,\n",
            "A backpack with secrets it hides.\n",
            "Its fabric gleams with an ethereal hue,\n",
            "A portal to realms both old and new.\n",
            "\n",
            "With a whisper, it opens wide,\n",
            "Revealing treasures it cannot hide.\n",
            "Books that whisper ancient lore,\n",
            "Maps that guide to distant shores.\n",
            "\n",
            "A compass points to hidden trails,\n",
            "Where adventure's call never fails.\n",
            "A flashlight illuminates the dark,\n",
            "Guiding through shadows, leaving its mark.\n",
            "\n",
            "A first aid kit, for wounds it heals,\n",
            "A blanket that comforts, a warmth it feels.\n",
            "A water bottle, quenching thirst,\n",
            "A snack to replenish, at its best.\n",
            "\n",
            "But its greatest power lies within,\n",
            "A space where dreams can begin.\n",
            "A place to store hopes and fears,\n",
            "A sanctuary where laughter cheers.\n",
            "\n",
            "With every step, it carries more,\n",
            "A weightless burden, a precious store.\n",
            "A symbol of wonder, a friend so true,\n",
            "The magic backpack, forever new.\n",
            "\n",
            "So let us wander, hand in hand,\n",
            "With this backpack, a treasure planned.\n",
            "For in its depths, we'll find our way,\n",
            "Through realms of magic, day by day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate to the Google Cloud Storage where the artifacts and other documents to run this lab are stored."
      ],
      "metadata": {
        "id": "qMH1OmZcpioi"
      },
      "id": "qMH1OmZcpioi"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "CRdrUuOEfC3s",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952555780,
          "user_tz": 0,
          "elapsed": 94,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "CRdrUuOEfC3s",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the document used for this exercise from the Google Cloud Storage"
      ],
      "metadata": {
        "id": "2-9oJHPKsJ-l"
      },
      "id": "2-9oJHPKsJ-l"
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://machine-learning-gemini/eBook-How-to-Build-a-Career-in-AI.pdf ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8xyvvmUfgIZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952562422,
          "user_tz": 0,
          "elapsed": 2630,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ee62e7ef-eb95-4f91-bb29-553007f31782"
      },
      "id": "t8xyvvmUfgIZ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://machine-learning-gemini/eBook-How-to-Build-a-Career-in-AI.pdf...\n",
            "/ [0 files][    0.0 B/  3.6 MiB]                                                \r/ [1 files][  3.6 MiB/  3.6 MiB]                                                \r\n",
            "Operation completed over 1 objects/3.6 MiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic RAG Pipeline\n",
        "In this example, we ingest the pdf, chunk into smaller sizes, create embeddings using our prefer model and index using VectorStoreIndex."
      ],
      "metadata": {
        "id": "QfDFfYBXvQ-g"
      },
      "id": "QfDFfYBXvQ-g"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "U73t-q3Adouf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952568550,
          "user_tz": 0,
          "elapsed": 6132,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "U73t-q3Adouf",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(documents), \"\\n\")\n",
        "print(len(documents), \"\\n\")\n",
        "print(type(documents[0]))\n",
        "print(documents[0])\n",
        "print(documents[1])"
      ],
      "metadata": {
        "id": "iaeD1tgmJK2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952568550,
          "user_tz": 0,
          "elapsed": 8,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "72e810f5-c491-4233-c964-1b9607fde392"
      },
      "id": "iaeD1tgmJK2S",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n",
            "41 \n",
            "\n",
            "<class 'llama_index.schema.Document'>\n",
            "Doc ID: b92643de-e93d-4aef-bd28-def6edd2f1e6\n",
            "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
            "How to  Build Your Career in AIA Simple Guide\n",
            "Doc ID: ef7f9dbf-f981-4c6f-87fa-f88ff4b1abc8\n",
            "Text: PAGE 2\"AI is the new  electricity. It will  transform and\n",
            "improve  all areas of human life.\" Andrew Ng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import Document\n",
        "\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ],
      "metadata": {
        "id": "acnCvjM1G4Br",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952568551,
          "user_tz": 0,
          "elapsed": 6,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "acnCvjM1G4Br",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "from llama_index import ServiceContext\n",
        "from llama_index.llms import Gemini\n",
        "\n",
        "\n",
        "llm = Gemini(model=\"models/gemini-pro\", temperature=0.1)\n",
        "\n",
        "# Create a service context using the Gemini LLM and the model\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
        ")\n",
        "index = VectorStoreIndex.from_documents([document],\n",
        "                                        service_context=service_context)"
      ],
      "metadata": {
        "id": "m5ifLvH0QxmD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952233093,
          "user_tz": 0,
          "elapsed": 19285,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "29beb701-300f-4323-db6b-1a9a6b60dce8"
      },
      "id": "m5ifLvH0QxmD",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "FAPZFdzhJX6L",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952235204,
          "user_tz": 0,
          "elapsed": 554,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "FAPZFdzhJX6L",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We run a sample Query to against the index to retrive the documents"
      ],
      "metadata": {
        "id": "XTyRSH4cvyY9"
      },
      "id": "XTyRSH4cvyY9"
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"What are steps to take when finding projects to build your experience?\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "75H8y7WCJdMv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707950716378,
          "user_tz": 0,
          "elapsed": 3426,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "09c4ee47-acb7-4251-d9d3-f5a92caa73e3"
      },
      "id": "75H8y7WCJdMv",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Join existing projects.\n",
            "2. Keep reading and talking to people.\n",
            "3. Focus on an application area.\n",
            "4. Develop a side hustle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://machine-learning-gemini/eval_questions.txt ."
      ],
      "metadata": {
        "id": "4RDSANf4PHHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952243530,
          "user_tz": 0,
          "elapsed": 4205,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "bb592d4c-4aa6-485e-cba0-20a4221f9a76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://machine-learning-gemini/eval_questions.txt...\n",
            "/ [1 files][  517.0 B/  517.0 B]                                                \n",
            "Operation completed over 1 objects/517.0 B.                                      \n"
          ]
        }
      ],
      "id": "4RDSANf4PHHO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here are some sample questions to help us with the evaluation and benchmarking of the RAG pipelines"
      ],
      "metadata": {
        "id": "-fNEvByTwB7V"
      },
      "id": "-fNEvByTwB7V"
    },
    {
      "cell_type": "code",
      "source": [
        "eval_questions = []\n",
        "with open('eval_questions.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        # Remove newline character and convert to integer\n",
        "        item = line.strip()\n",
        "        print(item)\n",
        "        eval_questions.append(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_vHm3w5cIfv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952582880,
          "user_tz": 0,
          "elapsed": 92,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ddea7a98-01c2-4f69-b17c-d1b21eb1795f"
      },
      "id": "2_vHm3w5cIfv",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the keys to building a career in AI?\n",
            "How can teamwork contribute to success in AI?\n",
            "What is the importance of networking in AI?\n",
            "What are some good habits to develop for a successful career?\n",
            "How can altruism be beneficial in building a career?\n",
            "What is imposter syndrome and how does it relate to AI?\n",
            "Who are some accomplished individuals who have experienced imposter syndrome?\n",
            "What is the first step to becoming good at AI?\n",
            "What are some common challenges in AI?\n",
            "Is it normal to find parts of AI challenging?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can try your own question:\n",
        "new_question = \"What is the right AI job for me?\"\n",
        "eval_questions.append(new_question)"
      ],
      "metadata": {
        "id": "Lc1ttbyscOXu",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952584819,
          "user_tz": 0,
          "elapsed": 120,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "Lc1ttbyscOXu",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mli6wlxAcQf9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952585680,
          "user_tz": 0,
          "elapsed": 126,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d67817ec-6edb-45c6-f56e-9c0a6bc8deb6"
      },
      "id": "mli6wlxAcQf9",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What are the keys to building a career in AI?', 'How can teamwork contribute to success in AI?', 'What is the importance of networking in AI?', 'What are some good habits to develop for a successful career?', 'How can altruism be beneficial in building a career?', 'What is imposter syndrome and how does it relate to AI?', 'Who are some accomplished individuals who have experienced imposter syndrome?', 'What is the first step to becoming good at AI?', 'What are some common challenges in AI?', 'Is it normal to find parts of AI challenging?', 'What is the right AI job for me?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up TruLens Feedback functions and dashboard for Evaluation and Benchmarking query results.\n",
        "\n",
        "Trulens helps you to objectively measure the quality and effectiveness of your LLM-based applications using feedback functions. Feedback functions help to programmatically evaluate the quality of inputs, outputs, and intermediate results, so that you can expedite and scale up experiment evaluation. Use it for a wide variety of use cases including question answering, summarization, retrieval-augmented generation, and agent-based applications."
      ],
      "metadata": {
        "id": "-ux_JqVtwOTO"
      },
      "id": "-ux_JqVtwOTO"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import JSON\n",
        "from trulens_eval import Tru, Feedback\n",
        "\n",
        "tru = Tru()\n",
        "\n",
        "tru.reset_database()"
      ],
      "metadata": {
        "id": "BB-4pG7JcS_c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952593133,
          "user_tz": 0,
          "elapsed": 5150,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbe01fb-bbbc-495c-965c-8b22e98ddb4a"
      },
      "id": "BB-4pG7JcS_c",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import custom utils.py .Utils.py contains custom functions to set up retreivers and feedback functions for a smooth run of this tutorial"
      ],
      "metadata": {
        "id": "DwCOwWZjxxfx"
      },
      "id": "DwCOwWZjxxfx"
    },
    {
      "cell_type": "code",
      "source": [
        "! rm utils.py\n",
        "!ls -ltr utils.py\n",
        "!gsutil cp gs://machine-learning-gemini/utils.py .\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "fh5xjhlZj4mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952595760,
          "user_tz": 0,
          "elapsed": 2631,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "26a045d1-be09-4d15-ac03-877c2390822e"
      },
      "id": "fh5xjhlZj4mr",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'utils.py': No such file or directory\n",
            "Copying gs://machine-learning-gemini/utils.py...\n",
            "/ [1 files][  5.5 KiB/  5.5 KiB]                                                \n",
            "Operation completed over 1 objects/5.5 KiB.                                      \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "importlib.import_module('utils')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQacB6e8nTpH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952596185,
          "user_tz": 0,
          "elapsed": 431,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4e8bb062-bee5-44ad-cdf7-65a22a4a2f9b"
      },
      "id": "iQacB6e8nTpH",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
            "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
            "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_prebuilt_trulens_recorder\n",
        "\n",
        "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
        "                                             app_id=\"Direct Query Engine\")"
      ],
      "metadata": {
        "id": "H2v5281A2Cci",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952254383,
          "user_tz": 0,
          "elapsed": 617,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "H2v5281A2Cci",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tru_recorder as recording:\n",
        "    for question in eval_questions:\n",
        "        response = query_engine.query(question)"
      ],
      "metadata": {
        "id": "RymUDAMw4Zba",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952317827,
          "user_tz": 0,
          "elapsed": 61928,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "RymUDAMw4Zba",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records, feedback = tru.get_records_and_feedback(app_ids=[])"
      ],
      "metadata": {
        "id": "rBtRFQ_zkdzw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952335732,
          "user_tz": 0,
          "elapsed": 459,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "rBtRFQ_zkdzw",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.head()"
      ],
      "metadata": {
        "id": "swhEGH6NkkQv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952337893,
          "user_tz": 0,
          "elapsed": 250,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8dadf2a1-ab7c-46b1-f284-6474a2a6b90d"
      },
      "id": "swhEGH6NkkQv",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                app_id                                           app_json  \\\n",
              "0  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "1  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "2  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "3  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "4  Direct Query Engine  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "\n",
              "                                                type  \\\n",
              "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
              "\n",
              "                                      record_id  \\\n",
              "0  record_hash_96ccbb406a23c9e6455f0f847d9cc09a   \n",
              "1  record_hash_6b95110b3efae8afb0258bddda2e44f1   \n",
              "2  record_hash_3d13e9b50c819471931b5f46d2f90d83   \n",
              "3  record_hash_9e715dde3dc6135b47e0577b487b5219   \n",
              "4  record_hash_dfb8af48b4f50907e5289c41da405fe9   \n",
              "\n",
              "                                               input  \\\n",
              "0    \"What are the keys to building a career in AI?\"   \n",
              "1    \"How can teamwork contribute to success in AI?\"   \n",
              "2      \"What is the importance of networking in AI?\"   \n",
              "3  \"What are some good habits to develop for a su...   \n",
              "4  \"How can altruism be beneficial in building a ...   \n",
              "\n",
              "                                              output tags  \\\n",
              "0  \"The keys to building a career in AI are learn...    -   \n",
              "1  \"Teamwork can contribute to success in AI by a...    -   \n",
              "2  \"Networking is important in AI because it can ...    -   \n",
              "3  \"Develop good habits in eating, exercise, slee...    -   \n",
              "4  \"Altruism can be beneficial in building a care...    -   \n",
              "\n",
              "                                         record_json  \\\n",
              "0  {\"record_id\": \"record_hash_96ccbb406a23c9e6455...   \n",
              "1  {\"record_id\": \"record_hash_6b95110b3efae8afb02...   \n",
              "2  {\"record_id\": \"record_hash_3d13e9b50c819471931...   \n",
              "3  {\"record_id\": \"record_hash_9e715dde3dc6135b47e...   \n",
              "4  {\"record_id\": \"record_hash_dfb8af48b4f50907e52...   \n",
              "\n",
              "                                           cost_json  \\\n",
              "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "2  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "3  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "4  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "\n",
              "                                           perf_json  \\\n",
              "0  {\"start_time\": \"2024-02-14T23:10:56.134866\", \"...   \n",
              "1  {\"start_time\": \"2024-02-14T23:11:02.566360\", \"...   \n",
              "2  {\"start_time\": \"2024-02-14T23:11:11.212540\", \"...   \n",
              "3  {\"start_time\": \"2024-02-14T23:11:15.826011\", \"...   \n",
              "4  {\"start_time\": \"2024-02-14T23:11:20.054960\", \"...   \n",
              "\n",
              "                           ts  Answer Relevance  Groundedness  \\\n",
              "0  2024-02-14T23:11:00.444236               0.5           1.0   \n",
              "1  2024-02-14T23:11:09.651930               0.9           0.7   \n",
              "2  2024-02-14T23:11:14.749454               0.3           1.0   \n",
              "3  2024-02-14T23:11:19.000269               1.0           1.0   \n",
              "4  2024-02-14T23:11:24.001644               0.8           1.0   \n",
              "\n",
              "   Context Relevance                             Answer Relevance_calls  \\\n",
              "0               0.95  [{'args': {'prompt': 'What are the keys to bui...   \n",
              "1               0.40  [{'args': {'prompt': 'How can teamwork contrib...   \n",
              "2               0.45  [{'args': {'prompt': 'What is the importance o...   \n",
              "3               0.25  [{'args': {'prompt': 'What are some good habit...   \n",
              "4               0.35  [{'args': {'prompt': 'How can altruism be bene...   \n",
              "\n",
              "                                  Groundedness_calls  \\\n",
              "0  [{'args': {'source': 'PAGE 1Founder, DeepLearn...   \n",
              "1  [{'args': {'source': 'Hopefully the previous c...   \n",
              "2  [{'args': {'source': 'Hopefully the previous c...   \n",
              "3  [{'args': {'source': 'Hopefully the previous c...   \n",
              "4  [{'args': {'source': 'Hopefully the previous c...   \n",
              "\n",
              "                             Context Relevance_calls  latency  total_tokens  \\\n",
              "0  [{'args': {'prompt': 'What are the keys to bui...        4             0   \n",
              "1  [{'args': {'prompt': 'How can teamwork contrib...        7             0   \n",
              "2  [{'args': {'prompt': 'What is the importance o...        3             0   \n",
              "3  [{'args': {'prompt': 'What are some good habit...        3             0   \n",
              "4  [{'args': {'prompt': 'How can altruism be bene...        3             0   \n",
              "\n",
              "   total_cost  \n",
              "0         0.0  \n",
              "1         0.0  \n",
              "2         0.0  \n",
              "3         0.0  \n",
              "4         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e9ac2f4-c31f-4d74-a5a5-1fd9f6e063f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_json</th>\n",
              "      <th>type</th>\n",
              "      <th>record_id</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>tags</th>\n",
              "      <th>record_json</th>\n",
              "      <th>cost_json</th>\n",
              "      <th>perf_json</th>\n",
              "      <th>ts</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance_calls</th>\n",
              "      <th>Groundedness_calls</th>\n",
              "      <th>Context Relevance_calls</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_96ccbb406a23c9e6455f0f847d9cc09a</td>\n",
              "      <td>\"What are the keys to building a career in AI?\"</td>\n",
              "      <td>\"The keys to building a career in AI are learn...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_96ccbb406a23c9e6455...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2024-02-14T23:10:56.134866\", \"...</td>\n",
              "      <td>2024-02-14T23:11:00.444236</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
              "      <td>[{'args': {'source': 'PAGE 1Founder, DeepLearn...</td>\n",
              "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_6b95110b3efae8afb0258bddda2e44f1</td>\n",
              "      <td>\"How can teamwork contribute to success in AI?\"</td>\n",
              "      <td>\"Teamwork can contribute to success in AI by a...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_6b95110b3efae8afb02...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2024-02-14T23:11:02.566360\", \"...</td>\n",
              "      <td>2024-02-14T23:11:09.651930</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.40</td>\n",
              "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
              "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
              "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_3d13e9b50c819471931b5f46d2f90d83</td>\n",
              "      <td>\"What is the importance of networking in AI?\"</td>\n",
              "      <td>\"Networking is important in AI because it can ...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_3d13e9b50c819471931...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2024-02-14T23:11:11.212540\", \"...</td>\n",
              "      <td>2024-02-14T23:11:14.749454</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.45</td>\n",
              "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
              "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
              "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_9e715dde3dc6135b47e0577b487b5219</td>\n",
              "      <td>\"What are some good habits to develop for a su...</td>\n",
              "      <td>\"Develop good habits in eating, exercise, slee...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_9e715dde3dc6135b47e...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2024-02-14T23:11:15.826011\", \"...</td>\n",
              "      <td>2024-02-14T23:11:19.000269</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
              "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
              "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Direct Query Engine</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
              "      <td>record_hash_dfb8af48b4f50907e5289c41da405fe9</td>\n",
              "      <td>\"How can altruism be beneficial in building a ...</td>\n",
              "      <td>\"Altruism can be beneficial in building a care...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_dfb8af48b4f50907e52...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2024-02-14T23:11:20.054960\", \"...</td>\n",
              "      <td>2024-02-14T23:11:24.001644</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
              "      <td>[{'args': {'source': 'Hopefully the previous c...</td>\n",
              "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e9ac2f4-c31f-4d74-a5a5-1fd9f6e063f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e9ac2f4-c31f-4d74-a5a5-1fd9f6e063f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e9ac2f4-c31f-4d74-a5a5-1fd9f6e063f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14e64f42-9895-42ea-a972-b67947229cb2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14e64f42-9895-42ea-a972-b67947229cb2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14e64f42-9895-42ea-a972-b67947229cb2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tru.run_dashboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBiqKGp3knqb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952349608,
          "user_tz": 0,
          "elapsed": 6698,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2b985cdb-9740-411e-c9e0-ad7a3d738489"
      },
      "id": "OBiqKGp3knqb",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "npx: installed 22 in 5.446s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://clever-cups-wash.loca.lt\n",
            "\n",
            "  Submit this IP Address: 35.238.6.193\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Advanced Rag Pipeline**"
      ],
      "metadata": {
        "id": "UfikiEEnlF7e"
      },
      "id": "UfikiEEnlF7e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Sentence Window retrieval"
      ],
      "metadata": {
        "id": "5zPN9BkStXmd"
      },
      "id": "5zPN9BkStXmd"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import Gemini\n",
        "\n",
        "llm = Gemini(model=\"models/gemini-pro\", temperature=0.1)"
      ],
      "metadata": {
        "id": "1gvxTRHDlJQ5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952605735,
          "user_tz": 0,
          "elapsed": 1351,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "1gvxTRHDlJQ5",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import build_sentence_window_index\n",
        "\n",
        "sentence_index = build_sentence_window_index(\n",
        "    document,\n",
        "    llm,\n",
        "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
        "    save_dir=\"sentence_index\"\n",
        ")"
      ],
      "metadata": {
        "id": "3aR5X6x-lOnU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952612867,
          "user_tz": 0,
          "elapsed": 7135,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c2c3c3-2a0c-4aee-ff36-295e9a299f19"
      },
      "id": "3aR5X6x-lOnU",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_sentence_window_query_engine\n",
        "\n",
        "sentence_window_engine = get_sentence_window_query_engine(sentence_index)\n"
      ],
      "metadata": {
        "id": "kLPAP2rslQrP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952617627,
          "user_tz": 0,
          "elapsed": 4764,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "kLPAP2rslQrP",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_response = sentence_window_engine.query(\n",
        "    \"how do I get started on a personal project in AI?\"\n",
        ")\n",
        "print(str(window_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "h1bN0dYZlSPc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952624440,
          "user_tz": 0,
          "elapsed": 6819,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b98f5e49-f6be-4d6c-ab1f-5b649befbdf8"
      },
      "id": "h1bN0dYZlSPc",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This context does not mention how to get started on a personal project in AI, so I cannot answer this question from the provided context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_prebuilt_trulens_recorder\n",
        "tru.reset_database()\n",
        "\n",
        "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
        "    sentence_window_engine,\n",
        "    app_id = \"Sentence Window Query Engine\"\n",
        ")"
      ],
      "metadata": {
        "id": "-OiQEvJWlVWt",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707952625215,
          "user_tz": 0,
          "elapsed": 795,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "-OiQEvJWlVWt",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tru_recorder_sentence_window as recording:\n",
        "    for question in eval_questions:\n",
        "        response = sentence_window_engine.query(question)\n",
        "        print(str(response))\n"
      ],
      "metadata": {
        "id": "tYK4FnF2lX_d"
      },
      "id": "tYK4FnF2lX_d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tru.get_leaderboard(app_ids=[])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "XDpur6EDlbF-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953152287,
          "user_tz": 0,
          "elapsed": 359,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "38140273-c02f-4964-974d-e2c3c51a546e"
      },
      "id": "XDpur6EDlbF-",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Answer Relevance  Groundedness  \\\n",
              "app_id                                                         \n",
              "Sentence Window Query Engine            0.6125      0.607143   \n",
              "\n",
              "                              Context Relevance  latency  total_cost  \n",
              "app_id                                                                \n",
              "Sentence Window Query Engine           0.584375   5.3125         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fd3db9d-dc3d-4616-8a87-14ae2a81d764\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sentence Window Query Engine</th>\n",
              "      <td>0.6125</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.584375</td>\n",
              "      <td>5.3125</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fd3db9d-dc3d-4616-8a87-14ae2a81d764')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fd3db9d-dc3d-4616-8a87-14ae2a81d764 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fd3db9d-dc3d-4616-8a87-14ae2a81d764');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# launches on http://localhost:8501/\n",
        "tru.run_dashboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "cMwYbtL9lemN",
        "executionInfo": {
          "status": "error",
          "timestamp": 1707953249011,
          "user_tz": 0,
          "elapsed": 93193,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "107e7a00-5eb4-4096-8bee-30a22622d19a"
      },
      "id": "cMwYbtL9lemN",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "Config file already exists. Skipping writing process.\n",
            "Credentials file already exists. Skipping writing process.\n",
            "npx: installed 22 in 2.505s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://brown-rules-smile.loca.lt\n",
            "\n",
            "Dashboard closed.\n",
            "Dashboard closed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dashboard failed to start in time. Please inspect dashboard logs for additional information.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-6f7a459e1224>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# launches on http://localhost:8501/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_dashboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trulens_eval/tru.py\u001b[0m in \u001b[0;36mrun_dashboard\u001b[0;34m(self, port, address, force, _dev)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstarted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mTru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdashboard_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    965\u001b[0m                 \u001b[0;34m\"Dashboard failed to start in time. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;34m\"Please inspect dashboard logs for additional information.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dashboard failed to start in time. Please inspect dashboard logs for additional information."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Auto Merging Retreival"
      ],
      "metadata": {
        "id": "ZuvKnrhRno3G"
      },
      "id": "ZuvKnrhRno3G"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5xoB0IzTaGcw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953033186,
          "user_tz": 0,
          "elapsed": 98,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "5xoB0IzTaGcw",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "import os\n",
        "from llama_index.llms import Gemini\n",
        "\n",
        "llm = Gemini(model=\"gemini-pro\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f_md4o1BaHGB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953034397,
          "user_tz": 0,
          "elapsed": 478,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "f_md4o1BaHGB",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "SlCpIMqnai9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953037136,
          "user_tz": 0,
          "elapsed": 1727,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "SlCpIMqnai9b",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(documents), \"\\n\")\n",
        "print(len(documents), \"\\n\")\n",
        "print(type(documents[0]))\n",
        "print(documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbqIcgxPaoC_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953038584,
          "user_tz": 0,
          "elapsed": 96,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "da87dc65-86b9-4cd9-a257-72d2ea822971"
      },
      "id": "PbqIcgxPaoC_",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n",
            "41 \n",
            "\n",
            "<class 'llama_index.schema.Document'>\n",
            "Doc ID: 6e839c67-8a12-4ef9-97f9-dc976b747c18\n",
            "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
            "How to  Build Your Career in AIA Simple Guide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import Document\n",
        "\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ],
      "metadata": {
        "id": "zaLh49ZjapvB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953040485,
          "user_tz": 0,
          "elapsed": 95,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "zaLh49ZjapvB",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.node_parser import HierarchicalNodeParser\n",
        "\n",
        "# create the hierarchical node parser w/ default settings\n",
        "node_parser = HierarchicalNodeParser.from_defaults(\n",
        "    chunk_sizes=[2048, 512, 128]\n",
        ")"
      ],
      "metadata": {
        "id": "AeU2SfFJar6B",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953041542,
          "user_tz": 0,
          "elapsed": 98,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "AeU2SfFJar6B",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = node_parser.get_nodes_from_documents([document])"
      ],
      "metadata": {
        "id": "V2SQ1HZkau42",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953043619,
          "user_tz": 0,
          "elapsed": 395,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "V2SQ1HZkau42",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.node_parser import get_leaf_nodes\n",
        "\n",
        "leaf_nodes = get_leaf_nodes(nodes)\n",
        "print(leaf_nodes[30].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCmfbqfgayAL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953044943,
          "user_tz": 0,
          "elapsed": 98,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0ecef7dd-d13d-462b-d6ea-4c4a3c3e87a7"
      },
      "id": "VCmfbqfgayAL",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But this became less important as numerical linear algebra libraries matured.\n",
            "Deep learning is still an emerging technology, so when you train a neural network and the \n",
            "optimization algorithm struggles to converge, understanding the math behind gradient \n",
            "descent, momentum, and the Adam  optimization algorithm will help you make better decisions. \n",
            "Similarly, if your neural network does something funny â€” say, it makes bad predictions on \n",
            "images of a certain resolution, but not others â€” understanding the math behind neural network \n",
            "architectures puts you in a better position to figure out what to do.\n",
            "Of course, I also encourage learning driven by curiosity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_by_id = {node.node_id: node for node in nodes}\n",
        "\n",
        "parent_node = nodes_by_id[leaf_nodes[30].parent_node.node_id]\n",
        "print(parent_node.text)"
      ],
      "metadata": {
        "id": "yLAwSbsta1AE"
      },
      "id": "yLAwSbsta1AE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext\n",
        "from llama_index.llms import Gemini\n",
        "\n",
        "\n",
        "llm = Gemini(model=\"gemini-pro\", temperature=0.1)\n",
        "\n",
        "auto_merging_context = ServiceContext.from_defaults(\n",
        "    llm=llm,\n",
        "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
        "    node_parser=node_parser,\n",
        ")"
      ],
      "metadata": {
        "id": "musU9Swua971",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953052202,
          "user_tz": 0,
          "elapsed": 1296,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "musU9Swua971",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf merging_index/\n",
        "!ls -ltr merging_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWUWx49HhCPp",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953054325,
          "user_tz": 0,
          "elapsed": 294,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "125bd8e7-605b-463d-f2ef-5a3b50fba5a9"
      },
      "id": "hWUWx49HhCPp",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'merging_index': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex, StorageContext\n",
        "from llama_index import set_global_service_context\n",
        "\n",
        "set_global_service_context(auto_merging_context)\n",
        "\n",
        "storage_context = StorageContext.from_defaults()\n",
        "storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "automerging_index = VectorStoreIndex(\n",
        "    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context\n",
        ")\n",
        "\n",
        "automerging_index.storage_context.persist(persist_dir=\"./merging_index\")"
      ],
      "metadata": {
        "id": "zLWSXrwybBCv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953109432,
          "user_tz": 0,
          "elapsed": 8094,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "zLWSXrwybBCv",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This block of code is optional to check\n",
        "# if an index file exist, then it will load it\n",
        "# if not, it will rebuild it\n",
        "\n",
        "import os\n",
        "from llama_index import VectorStoreIndex, StorageContext, load_index_from_storage\n",
        "from llama_index import load_index_from_storage\n",
        "\n",
        "if not os.path.exists(\"./merging_index\"):\n",
        "    storage_context = StorageContext.from_defaults()\n",
        "    storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "    automerging_index = VectorStoreIndex(\n",
        "            leaf_nodes,\n",
        "            storage_context=storage_context,\n",
        "            service_context=auto_merging_context\n",
        "        )\n",
        "\n",
        "    automerging_index.storage_context.persist(persist_dir=\"./merging_index\")\n",
        "else:\n",
        "    automerging_index = load_index_from_storage(\n",
        "        StorageContext.from_defaults(persist_dir=\"./merging_index\"),\n",
        "        service_context=auto_merging_context\n",
        "    )"
      ],
      "metadata": {
        "id": "k91KVCzqbDop",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953114214,
          "user_tz": 0,
          "elapsed": 725,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "k91KVCzqbDop",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
        "from llama_index.retrievers import AutoMergingRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.llms import Gemini\n",
        "\n",
        "\n",
        "automerging_retriever = automerging_index.as_retriever(\n",
        "    similarity_top_k=12\n",
        ")\n",
        "\n",
        "retriever = AutoMergingRetriever(\n",
        "    automerging_index.service_context,\n",
        "    automerging_retriever,\n",
        "    automerging_index.storage_context,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "rerank = SentenceTransformerRerank(top_n=6, model=\"BAAI/bge-reranker-base\")\n",
        "\n",
        "auto_merging_engine = RetrieverQueryEngine.from_args(\n",
        "    automerging_retriever, node_postprocessors=[rerank], verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "dp_KJ99zbHsa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953121415,
          "user_tz": 0,
          "elapsed": 4185,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "dp_KJ99zbHsa",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_merging_response = auto_merging_engine.query(\n",
        "    \"What is the importance of networking in AI?\"\n",
        ")"
      ],
      "metadata": {
        "id": "MTfr2EjBfaiK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953128701,
          "user_tz": 0,
          "elapsed": 5035,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "MTfr2EjBfaiK",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.response.notebook_utils import display_response\n",
        "\n",
        "display_response(auto_merging_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "wREZojs_fRBK",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707953130782,
          "user_tz": 0,
          "elapsed": 95,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6c51b5f4-8b19-41ac-b23a-b0d5d3f2c04b"
      },
      "id": "wREZojs_fRBK",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** Networking is important in AI because it can help you find potential employers, build up your community, and meet more people and make friends."
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}